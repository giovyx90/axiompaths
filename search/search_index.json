{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Benvenuto su Axiom Paths","text":"<p>Appunti ed esercizi open-source per studenti di matematica. Chiari, modulari, collegati agli argomenti d\u2019esame.</p> <p>Inizia da qui</p> <ul> <li>Analisi 1 \u2192 Limiti, Derivate</li> <li>Algebra Lineare \u2192 Spazi vettoriali</li> </ul>"},{"location":"analisi-1/esercizi/limiti-esercizi/","title":"Esercizi sui Limiti","text":"<p>Esempio 1 Calcolare: $$ \\lim_{x \\to 0} \\frac{\\sin x}{x} $$ Soluzione: Il limite vale \\(1\\).</p>"},{"location":"analisi-1/teoria/limiti/","title":"Limiti","text":"<p>Definizione: Sia \\(f : A \\subseteq \\mathbb{R} \\to \\mathbb{R}\\) e \\(x_0\\) punto di accumulazione per \\(A\\). Si dice che: $$ \\lim_{x \\to x_0} f(x) = L $$ se per ogni \\(\\varepsilon &gt; 0\\) esiste \\(\\delta &gt; 0\\) tale che...</p>"},{"location":"geometria-1/fogli/foglio-1/","title":"Geometria I \u2013 Foglio 1","text":""},{"location":"geometria-1/fogli/foglio-1/#esercizio-1","title":"Esercizio 1","text":"<p>Dimostrare che in uno spazio vettoriale \\(V\\), abbiamo che \\(0\\cdot v = O\\) per ogni \\(v \\in V\\) (qui \\(O \\in V\\) e \\(0 \\in \\mathbb{R}\\)) usando solo le altre propriet\u00e0 della definizione di spazio vettoriale.</p> <p>Dimostrazione</p> <ol> <li> <p>\\(0=0\\). Giust. Identit\u00e0 riflessiva nello scalare.</p> </li> <li> <p>\\(0+0=0\\). Giust. Propriet\u00e0 dell\u2019elemento neutro additivo in \\((\\mathbb{R},+)\\).</p> </li> <li> <p>\\((0+0)\\cdot v=0\\cdot v\\). Giust. Moltiplicazione per scalare \u00e8 un\u2019operazione definita per ogni scalare e vettore.</p> </li> <li> <p>\\(0\\cdot v + 0\\cdot v = 0\\cdot v\\). Giust. Distributivit\u00e0 della moltiplicazione per scalare rispetto alla somma degli scalari.</p> </li> <li> <p>Poich\u00e9 \\(0\\cdot v\\in V\\), esiste l\u2019opposto \\(-\\big(0\\cdot v\\big)\\). Sommo \\(-\\big(0\\cdot v\\big)\\) ad ambo i membri: \\((0\\cdot v + 0\\cdot v) + \\big(-0\\cdot v\\big) = 0\\cdot v + \\big(-0\\cdot v\\big)\\). Giust. Esistenza dell\u2019opposto (inverso additivo) in \\(V\\) e propriet\u00e0 di cancellazione della somma.</p> </li> <li> <p>Per associativit\u00e0 e definizione di opposto: \\(0\\cdot v + \\big(0\\cdot v + (-0\\cdot v)\\big) = O\\) e dunque \\(0\\cdot v = O\\). Giust. \\((x+(-x))=O\\).</p> </li> </ol> <p>\\(\\qed\\)</p> <p>Errori comuni</p> <ul> <li>Circolarit\u00e0: non assumere \\(0\\cdot v=O\\) a met\u00e0 dimostrazione.</li> <li>Notazione: distinguere \\(0\\) (scalare) da \\(O\\) (vettore nullo).</li> </ul>"},{"location":"geometria-1/fogli/foglio-1/#esercizio-2","title":"Esercizio 2","text":"<p>In uno spazio vettoriale provare che per ogni \\(t \\in \\mathbb{R}\\) abbiamo che \\(t \\cdot O = O\\).</p> <p>Dimostrazione</p> <ol> <li> <p>\\(O=O\\). Giust. Identit\u00e0 riflessiva in \\(V\\).</p> </li> <li> <p>\\(O+O=O\\). Giust. \\(O\\) \u00e8 neutro additivo in \\(V\\).</p> </li> <li> <p>\\(t\\cdot (O+O)=t\\cdot O\\). Giust. Moltiplicazione per scalare ben definita.</p> </li> <li> <p>\\(t\\cdot O + t\\cdot O = t\\cdot O\\). Giust. Distributivit\u00e0 della moltiplicazione per scalare rispetto alla somma di vettori.</p> </li> <li> <p>Sommo \\(-\\big(t\\cdot O\\big)\\) ad ambo i membri: \\((t\\cdot O + t\\cdot O) + (-t\\cdot O) = t\\cdot O + (-t\\cdot O)\\). Giust. Esistenza dell\u2019opposto e associativit\u00e0.</p> </li> <li> <p>Ottengo \\(t\\cdot O = O\\). Giust. \\(x+(-x)=O\\).</p> </li> </ol> <p>\\(\\qed\\)</p>"},{"location":"geometria-1/fogli/foglio-1/#esercizio-3","title":"Esercizio 3","text":"<p>Dedurre dall'esercizio 2 che se \\(t \\cdot v = O\\), allora \\(t = 0\\) oppure \\(v = O\\).</p> <p>Dimostrazione</p> <ol> <li> <p>Se \\(t=0\\), allora per l\u2019Esercizio 1 \\(0\\cdot v=O\\). Tesi verificata. Giust. Caso banale.</p> </li> <li> <p>Supponi \\(t\\neq 0\\). Allora esiste l\u2019inverso \\(t^{-1}\\in\\mathbb{R}\\) con \\(t^{-1}t=1\\). Giust. \\((\\mathbb{R}\\setminus\\{0\\},\\cdot)\\) \u00e8 un gruppo.</p> </li> <li> <p>Moltiplica l\u2019uguaglianza \\(t\\cdot v=O\\) per \\(t^{-1}\\): \\(t^{-1}\\cdot (t\\cdot v) = t^{-1}\\cdot O\\). Giust. Operazione per scalare su ambo i membri.</p> </li> <li> <p>Per associativit\u00e0 della moltiplicazione scalare e definizione di \\(1\\cdot v\\): \\((t^{-1}t)\\cdot v = 1\\cdot v = v\\). Quindi \\(v = t^{-1}\\cdot O\\). Giust. Propriet\u00e0 di unit\u00e0.</p> </li> <li> <p>Per l\u2019Esercizio 2, \\(t^{-1}\\cdot O=O\\). Dunque \\(v=O\\). Giust. Proposizione precedente.</p> </li> <li> <p>Concludiamo: se \\(t\\neq 0\\) allora \\(v=O\\); quindi in generale \\(t=0\\) oppure \\(v=O\\). \\(\\qed\\)</p> </li> </ol>"},{"location":"geometria-1/fogli/foglio-1/#esercizio-4","title":"Esercizio 4","text":"<p>Sia \\(\\mathcal{P}\\) lo spazio dei polinomi reali e [ W={p\\in\\mathcal{P}: p(1)=p(2)=0}. ] Tesi. \\(W\\) \u00e8 un sottospazio vettoriale di \\(\\mathcal{P}\\).</p> <p>Dimostrazione</p> <ol> <li> <p>Zero in \\(W\\). Il polinomio nullo \\(p_0(x)\\equiv 0\\) soddisfa \\(p_0(1)=0\\) e \\(p_0(2)=0\\). Giust. Valutazione diretta.</p> </li> <li> <p>Chiusura per somma. Se \\(p_1,p_2\\in W\\), allora \\((p_1+p_2)(1)=p_1(1)+p_2(1)=0+0=0\\) e \\((p_1+p_2)(2)=p_1(2)+p_2(2)=0+0=0\\). Giust. Linearit\u00e0 della valutazione.</p> </li> <li> <p>Chiusura per scalare. Se \\(p\\in W\\) e \\(\\lambda\\in\\mathbb{R}\\), allora \\((\\lambda p)(1)=\\lambda p(1)=\\lambda\\cdot 0=0\\) e analogamente per \\(x=2\\). Giust. Linearit\u00e0 della valutazione.</p> </li> <li> <p>Sono verificate le tre condizioni: \\(W\\) \u00e8 un s.s.v. \\(\\qed\\)</p> </li> </ol> <p>Schema rapido per i s.s.v.</p> <p>1) \\(O\\in W\\) \u2014 2) chiusura per somma \u2014 3) chiusura per scalare.</p>"},{"location":"geometria-1/fogli/foglio-1/#esercizio-5","title":"Esercizio 5*","text":"<p>Per quali \\(p\\in\\mathcal{P}\\) il grafico \\(\\Gamma=\\{(x,p(x)) : x\\in\\mathbb{R}\\}\\subset\\mathbb{R}^2\\) \u00e8 un sottospazio?</p> <p>Tesi. Esattamente per \\(p(x)=ax\\) (\\(a\\in\\mathbb{R}\\)) o \\(p\\equiv 0\\).</p> <p>Dimostrazione (passi chiave)</p> <ol> <li> <p>Origine. Se \\(\\Gamma\\) \u00e8 s.s.v., allora \\((0,0)\\in\\Gamma\\), quindi \\(p(0)=0\\). Giust. Un s.s.v. contiene il vettore nullo.</p> </li> <li> <p>Somma. Se \\((x_1,p(x_1))\\) e \\((x_2,p(x_2))\\) sono in \\(\\Gamma\\), la loro somma \\((x_1+x_2,\\; p(x_1)+p(x_2))\\) deve stare in \\(\\Gamma\\).    Quindi per ogni \\(x_1,x_2\\):    [    p(x_1+x_2)=p(x_1)+p(x_2).    ] Giust. Chiusura per somma: equazione di Cauchy additiva.</p> </li> <li> <p>Scalari. Per ogni \\(\\lambda\\in\\mathbb{R}\\), \\(\\lambda(x,p(x))=(\\lambda x,\\lambda p(x))\\in\\Gamma\\) implica    [    p(\\lambda x)=\\lambda\\,p(x)\\quad\\text{per ogni }x,\\lambda.    ] Giust. Chiusura per prodotto per scalare: omogeneit\u00e0 di grado 1.</p> </li> <li> <p>Conclusione. Un polinomio che \u00e8 additivo e omogeneo di grado 1 \u00e8 necessariamente lineare senza termine noto: \\(p(x)=ax\\).    Polinomi di grado \\(\\ge 2\\) violano l\u2019additivit\u00e0 (es. \\(x^2\\): \\(1^2+3^2\\neq (1+3)^2\\)). \\(\\qed\\)</p> </li> </ol>"},{"location":"geometria-1/fogli/foglio-1/#esercizio-6","title":"Esercizio 6","text":"<p>In \\(M_{2,2}(\\mathbb{R})\\) si consideri [ W={A\\in M_{2,2}(\\mathbb{R}) : A=-A^{T}}. ] Tesi. \\(W\\) \u00e8 un sottospazio di \\(M_{2,2}(\\mathbb{R})\\).</p> <p>Dimostrazione</p> <ol> <li> <p>Forma generale. Se \\(A=-A^T\\) con \\(A=\\begin{pmatrix}a&amp;b\\\\ c&amp;d\\end{pmatrix}\\), allora dai coefficienti diagonali \\(a=-a\\) e \\(d=-d\\) segue \\(a=d=0\\). Inoltre \\(c=-b\\).    Quindi ogni \\(A\\in W\\) \u00e8 del tipo    [    A=\\begin{pmatrix}0&amp;b\\ -b&amp;0\\end{pmatrix},\\quad b\\in\\mathbb{R}.    ]    Giust. Definizione di trasposta e uguaglianza di matrici.</p> </li> <li> <p>Chiusura per somma. Siano \\(A_1,A_2\\in W\\). Allora \\(A_1=-A_1^T\\) e \\(A_2=-A_2^T\\).    [    (A_1+A_2)^T=A_1^T+A_2^T=-(A_1+A_2).    ]    Quindi \\(A_1+A_2\\in W\\). Giust. Linearit\u00e0 della trasposizione.</p> </li> <li> <p>Chiusura per scalare. Per \\(\\lambda\\in\\mathbb{R}\\) e \\(A\\in W\\):    [    (\\lambda A)^T=\\lambda A^T=\\lambda(-A)=-(\\lambda A),    ]    dunque \\(\\lambda A\\in W\\). Giust. Linearit\u00e0 della trasposizione e propriet\u00e0 del prodotto per scalare.</p> </li> <li> <p>Zero in \\(W\\). La matrice nulla \\(0\\) verifica \\(0=-0^T\\). Giust. Trasposta di zero \u00e8 zero.</p> </li> <li> <p>Verificate le tre condizioni, \\(W\\) \u00e8 un s.s.v. di \\(M_{2,2}(\\mathbb{R})\\). \\(\\qed\\)</p> </li> </ol>"},{"location":"geometria-1/fogli/foglio-1/#esercizio-7","title":"Esercizio 7","text":"<p>In \\(\\mathbb{R}^3\\): [ W={(x,y,z)\\in\\mathbb{R}^3: x+y+z=0},\\qquad U_k=L\\big((1,k,2)\\big). ] Determinare \\(k\\in\\mathbb{R}\\) per cui \\(W\\cup U_k\\) \u00e8 un s.s.v.</p> <p>Soluzione</p> <ol> <li> <p>\\(\\dim W=2\\) (vincolo lineare \\(x=-y-z\\): due variabili libere \\(y,z\\)). Giust. Parametrizzazione: \\((x,y,z)=y(-1,1,0)+z(-1,0,1)\\).</p> </li> <li> <p>\\(\\dim U_k=1\\) per ogni \\(k\\) (\u00e8 lo span di un vettore non nullo). Giust. Un solo generatore non nullo \\(\\Rightarrow\\) base.</p> </li> <li> <p>Fatto chiave. \\(W\\cup U_k\\) \u00e8 s.s.v. \\(\\Rightarrow\\) uno \u00e8 contenuto nell\u2019altro.    Poich\u00e9 \\(\\dim U_k=1&lt;2=\\dim W\\), l\u2019unico caso possibile \u00e8 \\(U_k\\subseteq W\\). Giust. Se fosse \\(W\\subseteq U_k\\), avremmo \\(2\\le 1\\), assurdo.</p> </li> <li> <p>Condizione di inclusione: il generatore \\((1,k,2)\\) deve soddisfare l\u2019equazione di \\(W\\):    [    1+k+2=0\\ \\Longrightarrow\\ k=-3.    ]</p> </li> <li> <p>Con \\(k=-3\\), \\(U_k\\subseteq W\\) e dunque \\(W\\cup U_k=W\\), che \u00e8 un s.s.v.    Con \\(k\\neq -3\\), l\u2019unione non \u00e8 chiusa per somma. \\(\\qed\\)</p> </li> </ol>"},{"location":"geometria-1/fogli/foglio-1/#esercizio-8","title":"Esercizio 8","text":"<p>Per \\(v_1,v_2\\in V\\), provare che [ L(v_1,v_2)=L(v_1)+L(v_2). ]</p> <p>Dimostrazione (per doppia inclusione)</p> <ol> <li> <p>\\(\\subseteq\\) Sia \\(x\\in L(v_1,v_2)\\). Allora \\(x=\\alpha v_1+\\beta v_2\\) per qualche \\(\\alpha,\\beta\\in\\mathbb{R}\\).    Scrivo \\(x=(\\alpha v_1)+(\\beta v_2)\\) con \\(\\alpha v_1\\in L(v_1)\\) e \\(\\beta v_2\\in L(v_2)\\).    Quindi \\(x\\in L(v_1)+L(v_2)\\). Giust. Definizione di somma di sottoinsiemi: \\(A+B=\\{a+b: a\\in A,\\ b\\in B\\}\\).</p> </li> <li> <p>\\(\\supseteq\\) Sia \\(y\\in L(v_1)+L(v_2)\\). Allora \\(y=a+b\\) con \\(a\\in L(v_1)\\), \\(b\\in L(v_2)\\).    Esistono \\(\\alpha,\\beta\\) con \\(a=\\alpha v_1\\), \\(b=\\beta v_2\\), dunque \\(y=\\alpha v_1+\\beta v_2\\in L(v_1,v_2)\\). Giust. Definizione di span.</p> </li> <li> <p>Le due inclusioni danno l\u2019uguaglianza: \\(L(v_1,v_2)=L(v_1)+L(v_2)\\). \\(\\qed\\)</p> </li> </ol>"},{"location":"geometria-1/fogli/foglio-1/#esercizio-9","title":"Esercizio 9","text":"<p>Sia \\(V\\) uno spazio vettoriale. Se \\(v_1,v_2\\in L(w_1,\\dots,w_n)\\), provare che [ L(v_1,v_2)\\subseteq L(w_1,\\dots,w_n). ]</p> <p>Dimostrazione</p> <ol> <li> <p>Poich\u00e9 \\(v_1,v_2\\in L(w_1,\\dots,w_n)\\), esistono coefficienti \\((\\alpha_i),(\\beta_i)\\) tali che    [    v_1=\\sum_{i=1}^n \\alpha_i w_i,\\qquad v_2=\\sum_{i=1}^n \\beta_i w_i.    ]</p> </li> <li> <p>Sia \\(x\\in L(v_1,v_2)\\). Allora \\(x=a v_1+b v_2\\) per qualche \\(a,b\\in\\mathbb{R}\\). Sostituendo:    [    x=a\\sum_{i=1}^n \\alpha_i w_i+b\\sum_{i=1}^n \\beta_i w_i     =\\sum_{i=1}^n (a\\alpha_i+b\\beta_i)\\,w_i \\in L(w_1,\\dots,w_n).    ]    Giust. Chiusura di \\(L(w_1,\\dots,w_n)\\) per combinazioni lineari.</p> </li> <li> <p>Quindi \\(L(v_1,v_2)\\subseteq L(w_1,\\dots,w_n)\\). \\(\\qed\\)</p> </li> </ol>"},{"location":"geometria-1/fogli/foglio-1/#esercizio-10","title":"Esercizio 10*","text":"<p>Siano \\(W_1,W_2\\subseteq V\\) s.s.v. Se \\(W_1\\cup W_2\\) \u00e8 un s.s.v., mostrare che [ W_1\\subseteq W_2\\quad\\text{oppure}\\quad W_2\\subseteq W_1. ]</p> <p>Dimostrazione (per assurdo)</p> <ol> <li> <p>Supponiamo non valga nessuna inclusione: \\(W_1\\nsubseteq W_2\\) e \\(W_2\\nsubseteq W_1\\). Giust. Negazione della tesi.</p> </li> <li> <p>Esistono allora    [    w\\in W_1\\setminus W_2,\\qquad u\\in W_2\\setminus W_1.    ]</p> </li> <li> <p>Poich\u00e9 \\(W_1\\cup W_2\\) \u00e8 s.s.v., \u00e8 chiuso per somma, dunque \\(w+u\\in W_1\\cup W_2\\). Giust. Propriet\u00e0 dei sottospazi.</p> </li> <li> <p>Caso A: \\(w+u\\in W_1\\). Allora \\(u=(w+u)-w\\in W_1\\) (chiusura di \\(W_1\\) per opposto e somma), ma questo contraddice \\(u\\notin W_1\\).</p> </li> <li> <p>Caso B: \\(w+u\\in W_2\\). Allora \\(w=(w+u)-u\\in W_2\\), contraddicendo \\(w\\notin W_2\\).</p> </li> <li> <p>Entrambi i casi sono impossibili: l\u2019assunzione iniziale \u00e8 falsa.    Dunque necessariamente \\(W_1\\subseteq W_2\\) oppure \\(W_2\\subseteq W_1\\). \\(\\qed\\)</p> </li> </ol>"},{"location":"geometria-1/teoria/spazi-vettoriali/","title":"Spazi Vettoriali","text":"<p>Definizione: Uno spazio vettoriale su un campo \\(\\mathbb{K}\\) \u00e8 una struttura \\((V, +, \\cdot)\\) tale che...</p>"}]}